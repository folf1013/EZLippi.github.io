---
layout: post
title: 秒杀系统优化
description: 秒杀系统优化
keywords: 秒杀，优化
categories : [案例]
tags : [高并发]
---

情人节的抽奖活动类似于一次低流量的秒杀，里面有很多值得优化的点。下面是从架构师之路中看到一些经验。

# 原因
- 对于im系统（qq），或者微博系统，每个人都有自己的数据。
- 对于秒杀系统（小米抢手机，12306抢票，库存只有一份）,所有人都会集中在这个时间段来读写这份数据。
 故最大的原因在于太多的请求读写同一份数据库数据。

# 优化方向
由于数据库中的数据有限，所有尽量把请求拦截在上游，到达数据库的请求基本和库存一致了。

## 将请求尽量拦截在系统上游
若所有的请求都打到了数据库上，数据库的读写冲突很严重，所有请求都会超时。典型是一列车只有2000张票，若是同时进来100w个请求，全部都会超时。就算全部成功，也只有2000个请求时有效的，还不如，拦截其他请求，只进入前面2000个请求。

## 充分利用缓存
秒杀系统基本读多写少的场景，而缓存是很抗读的。

# 手段
- 客户端
通过按钮置等限制用户在x秒内只能提交一次请求，避免用户不断重复的点击。

- 站点层
对uid进行请求计数和去重，避免js的for循环调用。同一个uid的查询，做页面缓存，x秒内到达站点的请求返回页面缓存的数据，只透过一个请求。

- 服务层拦截
服务层可以采用请求队列。对于写请求，做请求队列，每次只透过有限的请求去数据层，2000张票，只透过2000个写请求。  
对于读请求，cache抗。redis单机每秒可以超过10w个读请求。

- 业务优化
12306分段分时售票，将流量分摊；数据粒度粗化，只标记有票或者无票；业务逻辑的异步，下单和付款分开等。

- 数据库
大部分的请求都被拦截了，到达数据库的请求应该和票的库存一样多，压力并不大。


# 抽奖活动优化

- 每个用户前面4等奖不能重复抽中的设计：之前的设计为对用户id加锁(zk)，然后访问数据库判断是否中过前4等奖；这个步骤可以放到redis中通过读实现，不必访问库。




